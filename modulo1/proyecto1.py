from langchain_google_genai import ChatGoogleGenerativeAI
from langchain.prompts import PromptTemplate
from langchain.schema import AIMessage, HumanMessage, SystemMessage
import streamlit as st

# Configurar la pagina de la app
st.set_page_config(page_title="Chatbot B√°sico", page_icon="ü§ñ")
st.title("ü§ñ Chatbot B√°sico con LangChain")
st.markdown("Este es un *chatbot de ejemplo* construido con LangChain + Streamlit. ¬°Escribe tu mensaje abajo para comenzar!")


with st.sidebar:
    st.header("Configuraci√≥n")
    temperature = st.slider("Temperatura", 0.0, 1.0, 0.5, 0.1)
    model_name = st.selectbox("Modelo",["gemini-2.5-flash"])

    chat_model = ChatGoogleGenerativeAI(model=model_name, temperature=temperature)


# Inicializar el historial de mensajes
if "mensajes" not in st.session_state:
    st.session_state.mensajes = []

# Crear el template de prompt con comportamiento espec√≠fico
prompt_template = PromptTemplate(
    input_variables=["mensaje", "historial"],
    template="""Eres un asistente √∫til y amigable llamado ChatBot Pro. 

    Historial de conversaci√≥n:
    {historial}

    Responde de manera clara y concisa a la siguiente pregunta: {mensaje}"""
    )

cadena = prompt_template | chat_model
# Mostrar mensajes previos 

for msg in st.session_state.mensajes:
    if isinstance(msg, SystemMessage):
        # No muestro el mensaje por pantalla
        continue

    role = "assistant" if isinstance(msg, AIMessage) else "user"
    with st.chat_message(role):
        st.markdown(msg.content)

if st.button("üóëÔ∏è Nueva conversaci√≥n"):
    st.session_state.mensajes = []
    st.rerun()

# Cuadro de entrada de texto de usuario
pregunta = st.chat_input("Escribe tu mensaje: ")
if pregunta:
    # Mostrar mensaje en la interfaz
    with st.chat_message("user"):
        st.markdown(pregunta)

    try:
        with st.chat_message("assistant"):
            response_placeholder = st.empty()
            full_response = ""

            for chunk in cadena.stream({"mensaje":pregunta, "historial":st.session_state.mensajes}):
                full_response += chunk.content
                response_placeholder.markdown(full_response + "‚ñå")
            
            response_placeholder.markdown(full_response)

        # Almacenamos el mensaje en la memoria
        st.session_state.mensajes.append(HumanMessage(content=pregunta))
        # Generar respuesta 
        st.session_state.mensajes.append(AIMessage(content=full_response))

    except Exception as e:
        st.error(f"Error al generar respuesta: {str(e)}")
        st.info("Verifica que tu API Key de OpenAI est√© configurada correctamente.")
